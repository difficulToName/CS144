# CS 144 2023 Spring 实验总结

2023 暑假 两周时间完成

张路遥
手写用户态玩具TCP

**i5-13400**

**32G 双通道 3600 Mhz**

**Ubuntu 22.10 64 bit**

**Clang 15.0.7**



## Lab 0 自制ByteStream

**2023.7.9**

这个实验分为上下两个部分。第一个实验是写一个简单的收发器从http网页获取报文，这个很简单。第二个实验是写一个byte_stream，我们这里重点讲述第二个实验。

实验本身很简单，做完实验后得到的Throughput是**0.79Gbit/s**，这个数据太可怜了。我们决定优化一下。

我的编码习惯是：先写一个能用的版本，看看实验要求的逻辑是不是和我们写的一致，随后再做速度和逻辑上的优化。

一开始我用的是 std::queue，存储char，每次向队列里面装和弹出都很慢。

优化思路：

1. 使用现代C++的新feature
2. 切换数据结构
3. 不要一个一个往里面放字符，争取一次多放字符串

第一步优化很简单，我们只需要在适当的位置上std::move就可以了，再有就是注意emplace和push的使用

第二步优化考察我们对C++的理解，std::queue 是 std::duque的套壳版本，所以说std::queue速度的上限就是std::deque，上限的门槛取决于编译器的优化程度 https://stackoverflow.com/questions/59542801/why-is-deque-faster-than-queue

第三步我们一次把所有字符全部放进去，这样就减少了循环带来的时间浪费

此外，这个实验要求的Reader::peek()返回std::string_view，所以这个实验我们使用两个std::deque，这样我们在返回string_view 的时候直接到队列里面取就可以了。这个思路来自于：https://zhuanlan.zhihu.com/p/630739394

值得注意的是，每个string_view 对象都必须有依赖一个实际存在的std::string对象，在函数栈里面创建的临时变量建立的string_view传出后再访问会报错(null_ptr)



最终我们得到的吞吐速度 throughtput 为 **25.95Gbit/s**，这个速度能够满足大部分千兆网络的速度。

**总结：**

将原来的queue更换为deque

在一开始就存储string_view

修改存放数据的方式与方法



## Lab 1 自制重排器

**2023.7.11初次完成 7.15修改完成**

同Lab 0思路，我们先造一个能够运行的玩具版本，然后再优化。

从要求来看，最适合同时又最简单的数据结构就是哈希表 std::unorderedmap<uint64_t, char>

思路也很简单，我们只需要维护好窗口起始位置（也就是已经提交的数据位置）和哈希表中的数据。并且根据待插入的数据的大小和reassembler中剩余的存储空间这两个条件，根据政策插入数据。

同上，这样做得到的结果自然很难看，吞吐量 throughput只有0.3Gbit/s。下面我们就开始优化

1. 插入std::string而非字符
2. 插入的是字符，而字符代表的是一个区间，区间这种数据形式并不是很和哈希表合得来，强行在哈希表中搜索一个区间会使得哈希表O(1)的时间复杂度降低到O(n)，所以这里我们使用二叉树
3. 所有能够触发ByteStream对象完成push()操作的data数据直接在本过程中push出去，与之对应的，不能触发push操作的就存起来
4. 最后我们发现在数据量没有超过一定量（这个数字大概在50万上下）的时候，使用二叉树的速度不如线性结构（即使是双链表），所以我们**最终决定使用链表 也就是std::list**完成这个Lab

### 首先我们普及下概念和定义：

**window_position :**当前想要接收到的第一个报文编号

**capacity :**每次使用或者测试的时候我们会给定一个总容量，这个容量指的是bytestream和reassembler的容量和。每当：从bytestream中pop数据的时候capacity就会增加，向reassembler中添加数据的时候capacity就会减少

**capacity_available : **当前重排器能够使用的最大容量

**pending :**当前在重排器里面因为不连续所以还没有传给bytestream的数据量

**first_index :**给定数据的第一位的下标（总下标从0开始）

**data :**每次收到的数据本身

### 这里我们简单讲下逻辑：

首先判断给定的数据是不是需要的，这里判断条件包括：空数据、数据过前（数据的尾端碰不到window_position）、数据太靠后（数据的起始点在window + capacity_available 后面）

如果数据正好卡在了window_position上，那么截取我们需要的部分push给bytestream，向后移动window_position，移动完成后排空“完全在window_position之前的报文段”，同样的，如果在排除过后还有剩余报文卡在了window_position上，那么就提交应该提交的部分。

没有卡在window_position上的话，我们截取该报文可以保留的部分（应当舍弃的部分指的是太靠后，也就是超出window_position + capacity_available范围的部分），填充reassembler。

最后我们尝试合并这些报文，将零散的报文合并为同一个。

当**已经出现过is_last_substring并且std::list空了**之后关闭bytestream



最终的优化结果为13.70 Gbits

**总结：**

1. 很多时候顺序结构的查找速度并没有那么不堪，map和set类的数据结构仅仅适合查找但不适合频繁的写入和擦除
2. 断点调试固然好，但是在适当时候 cout 或者 printf 也有不可替代的作用
3. 没必要在一开始就搞太深的优化，在程序块里面使用临时变量保存一下中间量再std::move走是更好的选择，至于临时变量的空间开销，现代编译器会帮助我们完成这个工作的。
4. 学会使用git，养成写注释的良好习惯 : )



## Lab 2 TCP接收器

**2023.7.15**

### 下标转换器

本节内容分为两个子节，一是下标转换器，之所以要有下标转换器是因为在handout中提到：为了保证TCP的robustness和安全性，每次一方的发送端都会随机选用一个数字作为SYN的号码。选定的号码几乎不可能是0，但是重排器使用的号码却是从0开始的，且TCP交互中的SEQ和ACK编码是可能超过 *UINT32_MAX* 的，这时候SEQ就会从0开始。为了方便重排器干活儿，我们得自己写一个从SEQ/ACK编码转化到重排器使用的绝对编码。重排器可以使用的编码有 *UINT64_MAX* 之多，即使是用一个数字表示一个Byte，这些数字表示的数据也足够一次TCP收发了。

关于转化这件事，我们已知的消息有：

1. 一开始随机选定的 uint32_t ，我们叫他ISN（Initial Sequeuce Number）
2. 我们已知“现在的窗口位置”，也就是重排器那一节里面的窗口位置。

**Wrap32::wrap()** 这个函数非常好实现，给定一个ISN和向后偏移的位置，叫我们求对应的Wrap32。我们直接把它们加起来就可以了，溢出的话计算机会重新从0开始计算。

**Wrap32::unwrap()** 这个函数略难，给定Wrap32本身，窗口位置和ISN

我们先计算给定Wrap32的值减去ISN的值，我们把这个数字称为 offset ，并且把它和checkpoint做大小比较：

​	我们先来观察offset，offset在运算过程中有好几种可能

​		第一，给定的Wrap32刚刚过zero_point，也就是说这时候相减得到的是一个正数，这个正数对应的absolut num可能是它本身，也可能是加上了好几个2^32

​		第二，给定的Wrap32小于zero_point，这样一来相减得到的数字必然大于zero_point（计算机无符号数减法的特性）这时候我们断定：Wrap32已经经过了至少一个周期了

### TCP消息接收器（发往重排器）

两个函数，一个函数负责把接收到的消息传给重排器，另一个函数用来不断向发送方报告现在的窗口状态（窗口位置和窗口容量）

**第一个函数**的关键点有两个，一是在没有接收到带着SYN标签的Message不要接受消息，只有接收到了SYN标签过后才能使用开始传入数据。

第二是传给重排器的下标和unwrapper函数得出的绝对下标的关系，它们差一个1

第三是什么时候传给重排器last_string信号

**第二个函数**也比较简单，这里不多说了

## Lab 3 TCP发送器

**2023.7.20**

这个Lab 的文档写的比较烂，做了半天才看出来文档的要求

Lab逻辑：按规定发送消息，发送的TCP报文过了一阵时间时候如果还没有收到对应消息的ACK那么就重发。

这个Lab最关键的有两个函数，一个函数是发送（实际上是将要发送的TCP信息放在队列里面），另一个函数是接收端传回来的窗口消息。

为了保证发送逻辑符合文档要求，文档要求设计的程序包含额外两个数据窗口，一个是已经从数据流ByteStream中取出但还没有被对方承认接收的数据量（不管我们是否发送），另一个是**连续**重传的数据包个数。

按照要求，我们还要实现一个定时器，这里还有一些定时器一同参与的逻辑。首先，每当一个数据被真正发送之后开启计时器。其次，如果传输的消息超时并且不是因为对方窗口大小为0导致的，那么我们认为网络拥堵，我们将RTO时间翻倍并从零开始重新计时。最后，所有可能被重传的报文（所有发出去的但没有下文的报文都算是要被重传的报文）都被接受的话，停止计时器。

这个Lab仅仅是逻辑乱一些，难度不大，这里我们就讲一下关键的两个函数和数据结构。

**数据结构：**一个自制的计时器（不要使用真实世界里面的时间），两个队列分别用来存储“下一个要发送的TCP包”和“可能要被重传的数据包”和一些必要的变量。

**函数实现：**

push()函数，这个函数的一个参数是字节流，也就是ByteStream。我们根据当前的接收方窗口位置和窗口大小来决定到底要从字节流里面取多少数据，这里：

1. 从字节流中取数据可以使用byte_stream_helpers.cc 里面的read()函数
2. 在去数据的时候要注意两点：一是取的数据不要大于TCPConfg::MAX_PAYLOAD_SIZE 。再者，如果传回来的数据显示现在接收方的窗口容量为0的话，我们就认为此时的窗口大小为1，之所以这么做handout里面讲过，因为我们不发送数据的话我们就不能得到发送方的数据，想想，万一接收方的用户程序从ByteStream里面取了数据，现在窗口大小变大了呢  : )

放到队列里之后我们还要在“可能会重发”的队列里面再存一份副本，以便后续查找。

receive()函数，这个函数的唯一一个参数是对方传来的消息，这个函数要做的是：首先用自带的数据保存新传来的状态，其次根据传来的数据排除掉“可能重传”队列里面不再需要的数据，在这个过程中要注意计时器操作和“连续重传数”的操作调节



## Lab 4 链路层加壳

**2023.7.22**

这个实验和最后的实验相对简单，测试用例也不多。

实验如标题总结，这里的链路层设计的不是很好，本实验只用考虑两种报文，ARP和IPv4报文，其中有个防止ARP泛滥的功能用到了计时，这个功能应该被设计在ARP协议里面，而非链路层里面。

链路层会发送两种报文：IPv4和ARP报文，同时我们还要手动维护一个ARP缓存表，缓存表里面的数据30秒一刷新，知道对应MAC地并且对应ARP数据未过期的直接放入发送队列，否则放ARP请求报文入队列，对应的IPv4报文找地方存储。

太简单了，不想讲了，需要的话看代码吧。需要指出的是，逻辑虽然简单，但是写出逻辑清晰的代码还是需要一点点功底的。其中队列报文的操作写起来就相对混乱一些。



## Lab 5 最长前缀匹配-简单路由行为

**2023.7.23**

上来先给定一些路由规则，我们想办法记录下这些路由规则，最后根据路由规则转发报文。

这个实验也比较简单，其中值得注意的坑是：

1. 每次转发报文都要将 TTL - 1 ，对于马上就要过期的报文我们就直接丢弃
2. 我们在匹配前缀找子网的时候要先匹配规则中CIDR最大的，举个极端的例子：0.0.0.0/0 这个路由范围+CIDR的组合能够匹配一切给定的IPv4地址。

要完成从CIDR长度出发从大到小查找的操作可以使用二叉树作为数据结构。







